# -*- coding: utf-8 -*-
"""Copy of Capstone project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16HJPW9WdBMLvxhFFpkWR_LDvql0kOSmv

# Deteksi Penyakit pada Kulit Wajah Manusia

## Load Data
"""

!pip install -q kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d hilmiher/face-disease

!mkdir dataset

!unzip face-disease.zip -d dataset

"""## Image Augmentation"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

train_dir = os.path.join('/content/dataset/Dataset/train/')
val_dir = os.path.join('/content/dataset/Dataset/validation')

train_datagen = ImageDataGenerator(rescale=1./225,
                                   rotation_range = 20,
                                   zoom_range = 0.2,
                                   shear_range = 0.2,
                                   fill_mode = 'nearest')
val_datagen = ImageDataGenerator(rescale=1./225)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',   
)
validation_generator = train_datagen.flow_from_directory(
    val_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical', 
)

"""## Modelling

### Transfer Learning MobileNetV2
"""

import tensorflow as tf

image_size = 160
IMG_SHAPE = (image_size, image_size, 3)

#Create the base model from the pre-trained model MobileNet V2
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                              include_top=False,
                                              weights='imagenet')
base_model.trainable = False

"""### Sequential Model"""

model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 300x300 with 3 bytes color
    # This is the first convolution
    base_model,
    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),  
    tf.keras.layers.Dense(9, activation='softmax')
])

model.summary()

"""### Compile and Training"""

from tensorflow.keras.optimizers import RMSprop

model.compile(optimizer=RMSprop(learning_rate=1e-4),
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

history = model.fit(train_generator,
                    validation_data = validation_generator,
                    epochs = 70,
                    verbose=1)

"""### Save Model"""

model.save('saved_model/my_model.h5')

"""### Training Result Chart"""

import matplotlib.pyplot as plt
# Retrieve a list of accuracy results on training and validation data
# sets for each training epoch
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

# Retrieve a list of list results on training and validation data
# sets for each training epoch
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))

# Plot training and validation accuracy per epoch
plt.plot(epochs, acc)
plt.plot(epochs, val_acc)
plt.title('Training and validation accuracy')

plt.figure()

# Plot training and validation loss per epoch
plt.plot(epochs, loss)
plt.plot(epochs, val_loss)
plt.title('Training and validation loss')

"""## Model Testing"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
from PIL import Image

new_model = tf.keras.models.load_model('./saved_model/my_model.h5')
labels = ['blackhead', 'eksim', 'flek hitam', 'herpes', 'jerawat', 'milia', 'panu', 'rosacea', 'tinea fasialis']
input_size = (160,160)
def preprocess(img,input_size):
    nimg = img.convert('RGB').resize(input_size, resample= 0)
    img_arr = (np.array(nimg))/255
    return img_arr
def reshape(imgs_arr):
    return np.stack(imgs_arr, axis=0)
im = Image.open('/content/07AcnePittedScars.jpg')
X = preprocess(im,input_size)
X = reshape([X])
y = new_model.predict(X)

print( labels[np.argmax(y)], np.max(y) )